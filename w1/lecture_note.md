Lecture note
Xusen Yin
April 4, 2015

# Machine Learning on Spark

# week1 讲义

由于各位学员背景不同，基础知识的情况也不太一致，因此第一周的内容主要分为三个overviews，旨在首先可以统一本课程的一些大致脉络，其次对于已经懂得这些基础知识的同学算作一个回顾，对于还不知道这些内容的同学作为一个学习的起点和指导。需要注意的是，学习是个自我进步和不断回顾的过程，讲师在短短的数小时内所起到的职能是启发和引导，真正学习的过程是在课外所花费的时间上。讲师能力有限，在设计课程的过程中参考了多人的资料，随后会附上致谢列表。

## Spark overview

本周课程不打算在一个小时的时间内事无巨细的讲解Spark，也不打算向大家介绍Spark ABC。具体的使用，API的操作请查看Spark官方文档。Spark overview的主要目的是让大家能够尽量明晰Spark的自身特点、计算范式、编程模型、以及运行调度，以便以后在面临一些看似奇怪的代码时能分析它这么做背后的原因。

Spark自身的特点，诚如其名，“轻快灵巧”。轻指的是Spark core的设计精巧，代码量少，同时得益于Scala语言丰富的表达力。快说的是Spark上手快，对于初学者完全可以看作单机Scala的分布式版本，RDD的抽象容易掌握；其次是运行快，亚秒级延迟，使其完全可以胜任交互式操作。灵指的是不同层面的灵活性，实现层基于Scala trait实现不同策略的定制和mixin，原语层简单的算子扩展和数据源扩展，以及多语言绑定（Java，Python）。范式层从多迭代的批量操作到流处理，即席查询和图计算等。巧是指其实现借巧力，站在巨人的肩膀上，避免一些费力不讨好的设计。

从计算范式的角度来看，Spark时典型的数据并行，因此具有数据并行的优势和局限。粗粒度数据并行的RDD中每个数据元素要过相同的代码序列，因此其完全不能胜任细粒度异步的数据更新，这点从GraphX的实现可见端倪，从MLlib现有的一些算法实现也可管中窥豹。Spark采用函数式语义，包括RDD的不可修改，UDF的使用，transformation不会产生副作用，而是产生一个新的RDD等。这样导致每个stage内部的计算是幂等的，失败时可以简单通过重放来容错。

从编程模型的角度来看，Spark就是简单的“数据加变换”。其计算空间分为Spark空间和Scala空间，前者的计算是分布式的，在各个worker节点上执行，后者的计算是在单节点执行，具体说来实在Driver节点执行。Scala空间到Spark空间需要输入算子，如textFile，parallel等，Spark空间回到Scala空间需要action算子。

从运行调度的角度来看，主要分为两大部分。第一部分是从Spark代码到切好的DAG stage，第二个部分是从stage到一个个执行的task。前者发生在Driver和代码之间，由DAG调度起负责，后者发生在各个Driver和各个具体执行的Executor之间，由task调度器负责。

对每个RDD而言，action算子触发job的投递。transformation算子中的宽依赖算子触发新的stage切分，而窄依赖算子最终会被pipeline到一起，或者说叫做operator fusion亦可。每两个相互依赖的stages之间通过shuffle传递数据。

## Machine Learning overview

T. G. Dietterich在MLSS 2014的讲座中讲了机器学习的三个问题，通俗易懂的介绍了机器学习的一般问题。此处借用这三个问题，向大家阐明机器学习的来由，问题，和基本方法。

机器学习的原动力就是来改变软件的流程，由之前“推导”式的方式转变为“归纳总结”。传统的算法流程是领域专家给出解题思路，按照这种解题思路设计算法求解问题，即expert => logic => function(input): output。Machine learning的方法是收集问题领域的输入输出，在某种假设下总结出其背后的逻辑，模拟领域专家，即<input, output> => logic => expert。

此处以有监督学习为例。有监督学习的简单例子包括手写识别、疾病监测、人脸识别等。其解决问题的一般框架是

- 由某一未知分布（the expert）随机且独立的采样，作为训练样本：

- 学习算法（the assumption）分析样本数据并生成分类器；

- 从相同的数据采样得到新数据，由分类器给出分类结果；

- 以某种方式评估误差；

Machine learning的目标就是，找到可以最小化expected loss的函数。

以垃圾邮件检测为例，这里未知的分布就是给定的邮件及其标注（“是”垃圾邮件或者“不是”垃圾邮件）其背后隐含的分布。训练样本是用户标注好的一堆邮件。学习算法会在后续的课程中讲到，最简单的方法就是Naive Bayes。输出的分类器，对于Naive Bayes而言，是一个条件概率，即在给定邮件x的条件下，它是垃圾邮件的概率。测试样本为一封新的且有ground truth的邮件，用一个损失函数（loss function）评估误差。最直观的损失函数就是分对损失为0，分错损失为1，叫做0-1 loss。

就学习方法而言，machine learning有三种基本方法。一是学习一个分类器y=f(x)（如Perceptron），二是学习一个条件概率分布p(y|x)（如Logistic regression），三是学习一个联合概率分布p(x, y)（如Linear discriminate  analysis）。第一周的课里只会讲到第一种，其他的在后续课程中会涉及。

以perceptron为例，我们过一下机器学习算法的基本流程。（待补充）

## Graph computing overview

本周最后一节介绍一下图计算的基础知识。首先界定图计算和机器学习的关系。现实生活中的很多问题都可以用图来概括（依赖关系），像twitter friendship网络，call graph等等。而很多科学问题的结构也是图结构，如PageRank的问题，网页之间存在相互的链接。由此，许多科学问题的解法也是一种图算法。针对PageRank，它本身就是一种通过图上的迭代计算特征向量的过程。不仅如此，像协同过滤、梯度下降、置信传播等等多种常见的machine learning算法都能用图的模型概括出来。后面我们也会看到，图的编程模型极大简化了大规模机器学习算法的实现。

图计算最重要两个组成部分就是编程模型和计算引擎，这周的课程中我们只会简要介绍编程模型的内容，计算引擎的部分我们会在专门研讨GraphX的一周内详细分析。

我们以PageRank为例来看不同的编程模型对程序的影响。最简单的方法是直接用MapReduce来表达图计算，我们在Map中完成每个节点的计算任务，在Reduce中进行shuffle，为每个节点聚合其邻居节点送过来的消息。从代码上来看，计算部分和消息传递以及图的结构相互耦合在一起。

BSP（Bulk Synchronous Parallel）首先是各个节点并行完成自己的顶点程序（vertex program），之后每个节点向其邻居节点广播其内容更新，此处会有一个大同步等待所有节点完成信息交换。之后再用最新的消息重新进行顶点程序的计算，并以此类推。BSP模型较好的分离了顶点计算、消息传递、图的结构三部分内容，程序看起来清晰易懂。

BSP模型的barrier会导致很多问题。原理上来讲最佳的并行策略是全异步的执行。每个节点收集到自己计算足够多的消息之后便可执行，执行结束即可向其邻居节点广播更新。但是这种情况下时序问题难以确定，例如节点A的邻居为B和C，节点A在某时刻收到了节点B的消息(messageB, timeB), 以及节点C的消息(messageC, timeC)，那么节点A的计算到底是以B的逻辑时钟为准还是以C的逻辑时钟为准？抑或是要求逻辑时钟慢者追上逻辑时钟快者之后才开始计算？这里还需要很多内容要仔细考量。

